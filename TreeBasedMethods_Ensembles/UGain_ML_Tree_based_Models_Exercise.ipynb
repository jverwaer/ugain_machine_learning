{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **UGain ML Tree-based Models Exercise Notebook**"
      ],
      "metadata": {
        "id": "KrE9FZvJo_1J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Libraries**"
      ],
      "metadata": {
        "id": "zzyz8bLHpHLI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-rU_pRdAJEW",
        "outputId": "864eb33d-e65f-4968-ccf8-d618c79a881e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting auto-sklearn\n",
            "  Downloading auto-sklearn-0.15.0.tar.gz (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 22.9 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.21.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.2.0)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.3.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.7.3)\n",
            "Collecting liac-arff\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "Collecting pynisher<0.7,>=0.6.3\n",
            "  Downloading pynisher-0.6.4.tar.gz (11 kB)\n",
            "Collecting distro\n",
            "  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (57.4.0)\n",
            "Collecting pyrfr<0.9,>=0.8.1\n",
            "  Downloading pyrfr-0.8.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 44.0 MB/s \n",
            "\u001b[?25hCollecting smac<1.3,>=1.2\n",
            "  Downloading smac-1.2.tar.gz (260 kB)\n",
            "\u001b[K     |████████████████████████████████| 260 kB 54.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dask>=2021.12 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (2022.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (4.1.1)\n",
            "Collecting ConfigSpace<0.5,>=0.4.21\n",
            "  Downloading ConfigSpace-0.4.21-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 42.7 MB/s \n",
            "\u001b[?25hCollecting scikit-learn<0.25.0,>=0.24.0\n",
            "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 56.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (6.0)\n",
            "Requirement already satisfied: distributed>=2012.12 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (2022.2.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace<0.5,>=0.4.21->auto-sklearn) (3.0.9)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from ConfigSpace<0.5,>=0.4.21->auto-sklearn) (0.29.32)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask>=2021.12->auto-sklearn) (0.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from dask>=2021.12->auto-sklearn) (21.3)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask>=2021.12->auto-sklearn) (1.3.0)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from dask>=2021.12->auto-sklearn) (1.5.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask>=2021.12->auto-sklearn) (2022.8.2)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2012.12->auto-sklearn) (2.4.0)\n",
            "Requirement already satisfied: tornado>=5 in /usr/local/lib/python3.7/dist-packages (from distributed>=2012.12->auto-sklearn) (5.1.1)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2012.12->auto-sklearn) (5.4.8)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2012.12->auto-sklearn) (2.2.0)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2012.12->auto-sklearn) (7.1.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2012.12->auto-sklearn) (2.11.3)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2012.12->auto-sklearn) (1.7.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2012.12->auto-sklearn) (1.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->auto-sklearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->auto-sklearn) (2022.4)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd>=0.3.10->dask>=2021.12->auto-sklearn) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0->auto-sklearn) (1.15.0)\n",
            "Collecting emcee>=3.0.0\n",
            "  Downloading emcee-3.1.3-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2012.12->auto-sklearn) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->distributed>=2012.12->auto-sklearn) (2.0.1)\n",
            "Building wheels for collected packages: auto-sklearn, pynisher, smac, liac-arff\n",
            "  Building wheel for auto-sklearn (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for auto-sklearn: filename=auto_sklearn-0.15.0-py3-none-any.whl size=6641946 sha256=2cab5d498e9f53ca5dee6b3ded151582a6261f1dcb44023d4b1abc6cce3e2b14\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/57/ce/ca63ad74b90273f9a682028d187645a42dce5c5255228d46c8\n",
            "  Building wheel for pynisher (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynisher: filename=pynisher-0.6.4-py3-none-any.whl size=7043 sha256=aa8281e6bbb3fb3467781dbbf34c8a06968e895e8739499489b5b8dde772465b\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/71/95/7555ec3253e1ba8add72ae5febf1b015d297f3b73ba296d6f6\n",
            "  Building wheel for smac (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for smac: filename=smac-1.2-py3-none-any.whl size=215933 sha256=825383aaf7799e92b39f371a4e6aabd85cc51b3f7023e9de02c268e9442299c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/95/67/6afc6b04d3715070c853d0a9d7c7b1fb822def38671dfbbb9f\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11732 sha256=e9a1481a2a349ab5b52e0ef098f2980445ec8c5323eb8c4c379964d81179a94c\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/0f/15/332ca86cbebf25ddf98518caaf887945fbe1712b97a0f2493b\n",
            "Successfully built auto-sklearn pynisher smac liac-arff\n",
            "Installing collected packages: scikit-learn, pyrfr, pynisher, emcee, ConfigSpace, smac, liac-arff, distro, auto-sklearn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.2 which is incompatible.\u001b[0m\n",
            "Successfully installed ConfigSpace-0.4.21 auto-sklearn-0.15.0 distro-1.8.0 emcee-3.1.3 liac-arff-2.5.0 pynisher-0.6.4 pyrfr-0.8.3 scikit-learn-0.24.2 smac-1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install auto-sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Auto-Sklearn\n",
        "\n",
        "# Basic libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
        "\n",
        "# Sklearn\n",
        "## Data\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## Models\n",
        "from sklearn import tree\n",
        "from sklearn import ensemble\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "## Model Explaination\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "## Metrics\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# XGBoost\n",
        "import xgboost\n",
        "\n",
        "# Plotting\n",
        "import graphviz\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "\n",
        "# Auto-Sklearn\n",
        "try:\n",
        "  import autosklearn.regression\n",
        "  import autosklearn.metrics\n",
        "finally:\n",
        "  import autosklearn.regression\n",
        "  import autosklearn.metrics"
      ],
      "metadata": {
        "id": "3cK5O2zIAo_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load Dataset**"
      ],
      "metadata": {
        "id": "DNm_6IWVpM7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "diabetes_data = load_diabetes()\n",
        "predictors = diabetes_data['data']\n",
        "labels = diabetes_data['target']\n",
        "\n",
        "# Print description of the dataset\n",
        "print(diabetes_data['DESCR'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_i2qQJPAtwk",
        "outputId": "0af08d4b-3579-40d1-dd04-40d95703ddf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _diabetes_dataset:\n",
            "\n",
            "Diabetes dataset\n",
            "----------------\n",
            "\n",
            "Ten baseline variables, age, sex, body mass index, average blood\n",
            "pressure, and six blood serum measurements were obtained for each of n =\n",
            "442 diabetes patients, as well as the response of interest, a\n",
            "quantitative measure of disease progression one year after baseline.\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "  :Number of Instances: 442\n",
            "\n",
            "  :Number of Attributes: First 10 columns are numeric predictive values\n",
            "\n",
            "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
            "\n",
            "  :Attribute Information:\n",
            "      - age     age in years\n",
            "      - sex\n",
            "      - bmi     body mass index\n",
            "      - bp      average blood pressure\n",
            "      - s1      tc, total serum cholesterol\n",
            "      - s2      ldl, low-density lipoproteins\n",
            "      - s3      hdl, high-density lipoproteins\n",
            "      - s4      tch, total cholesterol / HDL\n",
            "      - s5      ltg, possibly log of serum triglycerides level\n",
            "      - s6      glu, blood sugar level\n",
            "\n",
            "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
            "\n",
            "Source URL:\n",
            "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
            "\n",
            "For more information see:\n",
            "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
            "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "seed = 0\n",
        "\n",
        "# Train - Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(predictors, \n",
        "                                                    labels, \n",
        "                                                    random_state=seed)"
      ],
      "metadata": {
        "id": "IclnVblmCYPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercises**"
      ],
      "metadata": {
        "id": "-P4ETF2DpPHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility functions\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "def get_rmse(model, predictors, labels):\n",
        "  predictions = model.predict(predictors)\n",
        "  rmse = mean_squared_error(labels, predictions, squared=False)\n",
        "  return rmse\n",
        "\n",
        "def rmse_loss(true_labels, pred_labels):\n",
        "  return mean_squared_error(true_labels, pred_labels, squared=False)\n",
        "\n",
        "score_function_decision_tree = make_scorer(rmse_loss, greater_is_better=False)"
      ],
      "metadata": {
        "id": "r3_WSu1CpbHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 1a: Fit Decision Tree (Regression)**"
      ],
      "metadata": {
        "id": "dMQO_lLxn1CK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create decision tree regressor object\n",
        "decision_tree_regressor = tree.DecisionTreeRegressor(random_state=seed)\n",
        "\n",
        "# Fit the training data to the regressor\n",
        "decision_tree_regressor = , ...# FILL HERE\n",
        "\n",
        "# Calculate root mean square error of the train and test sets\n",
        "train_rmse = get_rmse(decision_tree_regressor, ...# FILL HERE)\n",
        "test_rmse = get_rmse(decision_tree_regressor, ...# FILL HERE)\n",
        "\n",
        "# Verbose\n",
        "print(\"Train set root mean squared error is: {} and test set root mean squared error is: {}\".format(round(train_rmse, 4), \n",
        "                                                                                                    round(test_rmse, 4)))"
      ],
      "metadata": {
        "id": "2lttPcFBqog_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 1b: Search for the Best Cost-Complexity Pruning (alpha)**"
      ],
      "metadata": {
        "id": "njnxVPZmn988"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Call built-in method to compute the pruning path during Minimal Cost-Complexity Pruning.\n",
        "ccp_alphas = decision_tree_regressor.cost_complexity_pruning_path(X_train, y_train).ccp_alphas\n",
        "\n",
        "# Define parameter space to search\n",
        "param_grid = {... #FILL HERE (HINT: parameter name is 'cpp_alpha' and cpp_alphas has type numpy.ndarray)\n",
        "              ,}\n",
        "\n",
        "# Create decision tree regressor object\n",
        "decision_tree_regressor = tree.DecisionTreeRegressor(random_state=seed)\n",
        "\n",
        "# Perform grid search in the defined parameter space with cross validation\n",
        "CV_decision_tree_regressor = GridSearchCV(estimator=decision_tree_regressor, \n",
        "                                          param_grid=param_grid, \n",
        "                                          cv= 5, \n",
        "                                          scoring=score_function_decision_tree)\n",
        "CV_decision_tree_regressor.fit(...# FILL HERE)\n",
        "\n",
        "# Verbose best parameters from the GridSearchCV\n",
        "print('Best Parameters:', ...# FILL HERE)\n",
        "\n",
        "# Fit decision tree regressor model with best parameters\n",
        "decision_tree_regressor = tree.DecisionTreeRegressor(random_state=seed,\n",
        "                                                     ...# FILL HERE)\n",
        "decision_tree_regressor = decision_tree_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Calculate root mean square error of the train and test sets\n",
        "train_rmse = get_rmse(decision_tree_regressor, X_train, y_train)\n",
        "test_rmse = get_rmse(decision_tree_regressor, X_test, y_test)\n",
        "\n",
        "# Verbose\n",
        "print(\"Train set root mean squared error is: {} and test set root mean squared error is: {}\".format(round(train_rmse, 4), \n",
        "                                                                                                    round(test_rmse, 4)))"
      ],
      "metadata": {
        "id": "navd28PWwGci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 2a: Fit an Ensemble Model of Your Choice (Regression)**\n",
        "\n",
        "Helpful to search regression ensemble models, use websites;\n",
        "1. https://scikit-learn.org/stable/modules/ensemble.html\n",
        "2. https://xgboost.readthedocs.io/en/stable/python/python_api.html"
      ],
      "metadata": {
        "id": "siwKWc8DoDdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a ensemble regressor object\n",
        "ensemble_regressor = ...# FILL HERE\n",
        "\n",
        "# Fit the training data to the ensemble regressor\n",
        "ensemble_regressor = ...# FILL HERE\n",
        "\n",
        "# Calculate root mean square error of the train and test sets\n",
        "train_rmse = get_rmse(ensemble_regressor, X_train, y_train)\n",
        "test_rmse = get_rmse(ensemble_regressor, X_test, y_test)\n",
        "print(\"Train set root mean squared error is: {} and test set root mean squared error is: {}\".format(round(train_rmse, 4), \n",
        "                                                                                                    round(test_rmse, 4)))"
      ],
      "metadata": {
        "id": "1L8U6yfN6gBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 2b: Search Hyperparameter Space of your Choice of Model**"
      ],
      "metadata": {
        "id": "or9sU2MhoPC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameter space to search\n",
        "param_grid = {\n",
        "  ...# FILL HERE\n",
        "}\n",
        "\n",
        "# Create ensemble tree regressor object\n",
        "ensemble_regressor = ...# FILL HERE\n",
        "\n",
        "# Perform grid search in the defined parameter space with cross validation\n",
        "CV_ensemble_regressor = GridSearchCV(estimator=ensemble_regressor, \n",
        "                                    param_grid=param_grid, \n",
        "                                    cv= 5, \n",
        "                                    scoring=score_function_decision_tree)\n",
        "CV_ensemble_regressor.fit(...# FILL HERE)\n",
        "\n",
        "# Verbose best parameters from the GridSearchCV\n",
        "print('Best Parameters:', CV_ensemble_regressor.best_params_)\n",
        "\n",
        "# Fit ensemble regressor model with best parameters\n",
        "ensemble_regressor = ...# FILL HERE\n",
        "                              \n",
        "ensemble_regressor = ensemble_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Calculate root mean square error of the train and test sets\n",
        "train_rmse = get_rmse(ensemble_regressor, X_train, y_train)\n",
        "test_rmse = get_rmse(ensemble_regressor, X_test, y_test)\n",
        "\n",
        "# Verbose\n",
        "print(\"Train set root mean squared error is: {} and test set root mean squared error is: {}\".format(round(train_rmse, 4), \n",
        "                                                                                                    round(test_rmse, 4)))"
      ],
      "metadata": {
        "id": "s-B1blm66t_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 2c: Plot: Ensemble Regressor Feature Importance**"
      ],
      "metadata": {
        "id": "AFuoGF2dS6Bs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform permutation feature importance using the best ensemble model\n",
        "permutation_importance_result = ... # FILL HERE\n",
        "\n",
        "# Extract the mean and standard deviation of the feature importances from the results and create Pandas Dataframe\n",
        "forest_importances = pd.DataFrame({\"importances\" : permutation_importance_result.importances_mean, \n",
        "                                   \"stdev\" : permutation_importance_result.importances_std }, \n",
        "                                   index=diabetes_data['feature_names']).sort_values(\"importances\", ascending=False).iloc[:5]\n",
        "\n",
        "# Plot the feature importances\n",
        "fig, ax = plt.subplots(figsize=(15,8))\n",
        "forest_importances[\"importances\"].plot.bar(yerr=forest_importances.stdev, ax=ax)\n",
        "ax.set_title(\"Feature importances using permutation on test data\")\n",
        "ax.set_ylabel(\"Mean RMSE decrease\")\n",
        "ax.set_ylim(bottom=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F7ccXTv4TIDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 3 (Bonus): Use AutoML to Improve RMSE Metric**"
      ],
      "metadata": {
        "id": "oTTWj4mZod5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define AutoML regression model from Auto-Sklearn\n",
        "automl = autosklearn.regression.AutoSklearnRegressor(time_left_for_this_task=120,\n",
        "                                                     metric=autosklearn.metrics.root_mean_squared_error)\n",
        "\n",
        "# Fit AutoML regression model \n",
        "...# FILL HERE\n",
        "\n",
        "# Calculate root mean square error of the train and test sets\n",
        "train_rmse = ...# FILL HERE\n",
        "test_rmse = ...# FILL HERE\n",
        "\n",
        "# Verbose\n",
        "print(\"Train set root mean squared error is: {} and test set root mean squared error is: {}\".format(round(train_rmse, 4), \n",
        "                                                                                                    round(test_rmse, 4)))\n",
        "# Verbose Final Model Leaderboard from AutoML\n",
        "print(automl.leaderboard())"
      ],
      "metadata": {
        "id": "Zswfyv6J00gT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}